{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricCui2005/Chuffin/blob/main/Chuffin_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3mRDH-EzCnM",
        "outputId": "0b9cea87-4edf-4183-ec0f-e651363aa6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)\n",
        "\n",
        "# Gooooogle Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oc4JuyfYonve"
      },
      "outputs": [],
      "source": [
        "#@title Renaming and \"Labeling\" Chihuahua Images\n",
        "\n",
        "# Directory with the chihuahua images\n",
        "dir = '/content/drive/Shareddrives/Choofin/1124 Chihuahuas'\n",
        "files = os.listdir(dir)\n",
        "\n",
        "os.chdir('/content/drive/Shareddrives/Choofin/1124 Chihuahuas')\n",
        "\n",
        "# Define a function to rename files\n",
        "def rename_files():\n",
        "    for i in range(len(files)):\n",
        "        new_name = f\"c_{i}\"\n",
        "        os.rename(files[i], new_name)\n",
        "\n",
        "# Call the main function to rename files\n",
        "rename_files()\n",
        "files = os.listdir(dir)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DN-tIzCbrAIB"
      },
      "outputs": [],
      "source": [
        "#@title Renaming and \"Labeling\" Muffin Images\n",
        "\n",
        "# Directory with the chihuahua images\n",
        "dir = '/content/drive/Shareddrives/Choofin/muffin'\n",
        "files = os.listdir(dir)\n",
        "\n",
        "os.chdir('/content/drive/Shareddrives/Choofin/muffin')\n",
        "\n",
        "# Define a function to rename files\n",
        "def rename_files():\n",
        "    for i in range(len(files)):\n",
        "        new_name = f\"m_{i}\"\n",
        "        os.rename(files[i], new_name)\n",
        "\n",
        "# Call the main function to rename files\n",
        "rename_files()\n",
        "files = os.listdir(dir)\n",
        "print(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tm35TnnNL-vp"
      },
      "outputs": [],
      "source": [
        "#@title Clearing a folder\n",
        "# Specify the folder you want to clear\n",
        "folder_path = '/content/drive/Shareddrives/Choofin/train'  # Change this to your folder path\n",
        "\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "    # List all files and directories in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        try:\n",
        "            # If it is a file, delete it\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)\n",
        "            # If it is a directory, delete it and all its contents\n",
        "            elif os.path.isdir(file_path):\n",
        "                # For deleting directories and their contents, you can use shutil.rmtree\n",
        "                import shutil\n",
        "                shutil.rmtree(file_path)\n",
        "            print(f\"{file_path} is deleted.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
        "else:\n",
        "    print(f\"The specified path does not exist: {folder_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZOdvjjzYrZJA"
      },
      "outputs": [],
      "source": [
        "#@title Combining Dataset\n",
        "\n",
        "source_folder = '/content/drive/Shareddrives/Choofin/1124 Chihuahuas'\n",
        "destination_folder = '/content/drive/Shareddrives/Choofin/train'\n",
        "\n",
        "# List all files and folders in the source folder\n",
        "for item in os.listdir(source_folder):\n",
        "    source_item = os.path.join(source_folder, item)\n",
        "    destination_item = os.path.join(destination_folder, item)\n",
        "\n",
        "    # Move each item to the destination folder\n",
        "    if os.path.isfile(source_item):\n",
        "        print(f\"Copying {source_item}\")\n",
        "        shutil.copy(source_item, destination_item)\n",
        "\n",
        "source_folder = '/content/drive/Shareddrives/Choofin/1088 Muffins'\n",
        "destination_folder = '/content/drive/Shareddrives/Choofin/train'\n",
        "\n",
        "# List all files and folders in the source folder\n",
        "for item in os.listdir(source_folder):\n",
        "    source_item = os.path.join(source_folder, item)\n",
        "    destination_item = os.path.join(destination_folder, item)\n",
        "\n",
        "    # Move each item to the destination folder\n",
        "    if os.path.isfile(source_item):\n",
        "        print(f\"Copying {source_item}\")\n",
        "        shutil.copy(source_item, destination_item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDU4gkeosgKQ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Creating the Label Set\n",
        "files = os.listdir('/content/drive/Shareddrives/Choofin/train')\n",
        "print(len(files))\n",
        "\n",
        "# Training labels\n",
        "label_set = []\n",
        "\n",
        "for img in files:\n",
        "  if(chr(ord(img[0])) == 'm'):\n",
        "    label_set.append(0)\n",
        "  elif(chr(ord(img[0])) == 'c'):\n",
        "    label_set.append(1)\n",
        "\n",
        "print(len(label_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpCcKxajH5as",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Verifying Labels\n",
        "print(len(files))\n",
        "print(len(label_set))\n",
        "\n",
        "for i in range(len(files)):\n",
        "  if (files[i][0] == 'c'):\n",
        "     print(label_set[i] == 1)\n",
        "  elif (files[i][0] == 'm'):\n",
        "     print(label_set[i] == 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLojkQwZbNA0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Converting Images to (64, 64, 3) and loading X\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "def preprocess_images(folder_path, image_size=(64, 64)):\n",
        "    images = []\n",
        "    file_names = os.listdir(folder_path)\n",
        "\n",
        "    for file_name in file_names:\n",
        "        print(f\"Converting {file_name}\")\n",
        "        # Load image\n",
        "        img_path = os.path.join(folder_path, file_name)\n",
        "        img = load_img(img_path, target_size=image_size)\n",
        "\n",
        "        # Convert image to array and normalize\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "\n",
        "        images.append(img_array)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Example usage\n",
        "folder_path = '/content/drive/Shareddrives/Choofin/train'\n",
        "processed_images = preprocess_images(folder_path)\n",
        "\n",
        "print(processed_images.shape)  # Should show (number_of_images, 64, 64, 3)\n",
        "X = processed_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_wOU_BB_Hdo"
      },
      "outputs": [],
      "source": [
        "#@title Loading the Data\n",
        "from PIL import Image\n",
        "import numpy\n",
        "import os\n",
        "directory = '/content/drive/Shareddrives/Choofin/train'\n",
        "\n",
        "def load_data():\n",
        "  X = []\n",
        "  Y =  label_set # 1 means dog, 0 means muffin\n",
        "  labels = np.array(Y)\n",
        "  for file in os.listdir(directory):\n",
        "    print(file)\n",
        "    file_path = os.path.join(directory, file)\n",
        "    img = Image.open(file_path)\n",
        "    pix_val = list(img.getdata())\n",
        "    pix_val_flat = [x for sets in pix_val for x in sets] # turns list of tuples into just a single list\n",
        "    normalized_pix_val = [float(x / 255) for x in pix_val_flat]\n",
        "    X.append(normalized_pix_val)\n",
        "  data = np.array(X)\n",
        "  return data, labels\n",
        "\n",
        "X, Y = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kbgX0EpcHUG"
      },
      "outputs": [],
      "source": [
        "#@title Printing Shape\n",
        "Y = np.array(label_set)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXuRzwizgUzO"
      },
      "outputs": [],
      "source": [
        "#@title Perceptron Model Architecture\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(49152,)),    #specify input size\n",
        "        Dense(64, activation='ReLU', kernel_regularizer=regularizers.L1(0.0001)),\n",
        "        Dense(32, activation='ReLU', kernel_regularizer=regularizers.L1(0.00002)),\n",
        "        Dense(16, activation='ReLU', kernel_regularizer=regularizers.L1(0.00004)),\n",
        "        Dense(1,  activation='sigmoid')\n",
        "    ], name = \"my_model\"\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "[layer1, layer2, layer3, layer4] = model.layers\n",
        "print(model.layers[3].weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyzdKvj9NAWE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title CNN Architecture\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "# Convolutional layer that learns 32 filters using a 3x3 kernel\n",
        "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(64, 64, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Additional convolutional layers\n",
        "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (4, 4), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattening the 3D outputs to 1D before passing them to a Dense layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
        "\n",
        "# Output layer for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KH-w8v8qhYMR"
      },
      "outputs": [],
      "source": [
        "#@title Compiling the Model\n",
        "import keras\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# model.fit(\n",
        "#     X,Y,\n",
        "#     batch_size=64,\n",
        "#     epochs=80\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80oTbtjUTFcG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title True vs Predicted Labels\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "# You do not need to modify anything in this cell\n",
        "\n",
        "m, n, o, p = X.shape\n",
        "\n",
        "fig, axes = plt.subplots(6,6, figsize=(6,6))\n",
        "fig.tight_layout(pad=0.1,rect=[0, 0.03, 1, 0.92]) #[left, bottom, right, top]\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    # Select random indices\n",
        "    random_index = np.random.randint(m)\n",
        "\n",
        "    # Select rows corresponding to the random indices and\n",
        "    # reshape the image\n",
        "    X_random_reshaped = X[random_index].reshape((64,64,3))\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(X_random_reshaped)\n",
        "\n",
        "    # Predict using the Neural Network\n",
        "    prediction = model.predict(X[random_index].reshape(1,64,64,3))\n",
        "    if prediction >= 0.5:\n",
        "        yhat = 1\n",
        "    else:\n",
        "        yhat = 0\n",
        "\n",
        "    # Display the label above the image\n",
        "    ax.set_title(f\"{Y[random_index]},{yhat}\")\n",
        "    ax.set_axis_off()\n",
        "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DICA4AppYwRN"
      },
      "outputs": [],
      "source": [
        "#@title Fitting the model for history purposes\n",
        "history = model.fit(X, Y, validation_split=0.2, epochs=60, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KNzMbNMkt_b"
      },
      "outputs": [],
      "source": [
        "#@title Graphing our model history\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# AUC plot\n",
        "auc = model.history.history['auc']\n",
        "val_auc = model.history.history['val_auc']\n",
        "\n",
        "epochs = range(1, len(auc) + 1)\n",
        "\n",
        "plt.plot(epochs, auc, 'bo', label='Training AUC')\n",
        "plt.plot(epochs, val_auc, 'b', label='Validation AUC')\n",
        "plt.title('Training and Validation AUC')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "batch_size = 32\n",
        "y_prediction = []\n",
        "\n",
        "for i in range(0, len(X), batch_size):\n",
        "    # Extract a batch of data\n",
        "    batch_X = X[i:i+batch_size]\n",
        "\n",
        "    # Predict for the batch\n",
        "    batch_prediction = model.predict(batch_X)\n",
        "\n",
        "    # Convert probabilities to class labels\n",
        "    batch_y_pred = (batch_prediction >= 0.5).astype(int)\n",
        "\n",
        "    # Collect the predictions for the batch\n",
        "    y_prediction.extend(batch_y_pred)\n",
        "\n",
        "y_pred = np.array(y_prediction)\n",
        "cm = confusion_matrix(Y, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeTM4s_LMQYj"
      },
      "outputs": [],
      "source": [
        "#@title Analyzing Incorrect Predictions\n",
        "false_positives = []\n",
        "false_negatives = []\n",
        "\n",
        "for i in range(len(Y)):\n",
        "    if Y[i] == 1 and y_pred[i] == 0:\n",
        "        false_negatives.append((X[i], Y[i], y_pred[i]))\n",
        "    elif Y[i] == 0 and y_pred[i] == 1:\n",
        "        false_positives.append((X[i], Y[i], y_pred[i]))\n",
        "\n",
        "total_samples = len(Y)\n",
        "false_negative_percentage = len(false_negatives) / total_samples * 100\n",
        "false_positive_percentage = len(false_positives) / total_samples * 100\n",
        "\n",
        "print(\"False Negative Percentage:\", false_negative_percentage)\n",
        "print(\"False Positive Percentage:\", false_positive_percentage)\n",
        "\n",
        "fig, axes = plt.subplots(6, 6, figsize=(6, 6))\n",
        "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92])  # [left, bottom, right, top]\n",
        "\n",
        "for i, (ax, (sample, true_label, _)) in enumerate(zip(axes.flat, false_positives)):\n",
        "    sample_reshaped = sample.reshape((64, 64, 3))\n",
        "    ax.imshow(sample_reshaped)\n",
        "\n",
        "    prediction = model.predict(sample.reshape(1, 64, 64, 3))\n",
        "    yhat = 1 if prediction >= 0.5 else 0\n",
        "\n",
        "    ax.set_title(f\"True: {true_label}, Predicted: {yhat}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "fig.suptitle(\"False Negatives: True Label vs. Predicted Label\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49d4KyOKdTcC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}